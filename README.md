# ğŸ“ SISU Daily Sync - Monitoramento de Notas de Corte

Este projeto Ã© uma ferramenta de automaÃ§Ã£o e engenharia de dados projetada para monitorar, coletar e armazenar o histÃ³rico das notas de corte do SISU. Ele foca nos cursos mais concorridos, construindo uma base de dados histÃ³rica robusta para anÃ¡lise de tendÃªncias.

## ğŸŒ Dashboard Online
Acesse a visualizaÃ§Ã£o dos dados em tempo real:  
ğŸš€ **[https://scraper-sisu.streamlit.app](https://scraper-sisu.streamlit.app)**

## ğŸ—ï¸ Arquitetura e PadrÃµes de Projeto
O sistema foi desenvolvido seguindo padrÃµes de engenharia de software para garantir escalabilidade e manutenÃ§Ã£o:

* **PadrÃ£o MVC (Model-View-Controller):**
    * **Model:** RepresentaÃ§Ã£o dos dados (vagas e modalidades).
    * **View:** Interface interativa desenvolvida em Streamlit.
    * **Controller:** OrquestraÃ§Ã£o da lÃ³gica de negÃ³cio e paralelismo.
* **Camada DAL (Data Access Layer):** Implementada via `SisuRepository`, isolando completamente a lÃ³gica de persistÃªncia de arquivos (CSV/JSON/TXT) das regras de negÃ³cio.
* **InjeÃ§Ã£o de DependÃªncia:** Facilitando a troca de provedores de dados (APIs) sem afetar o fluxo principal.

## ğŸš€ Diferenciais TÃ©cnicos

* **Alta Performance (Parallel Threading):** ImplementaÃ§Ã£o de `ThreadPoolExecutor` no Controller para realizar a coleta de mÃºltiplas faculdades simultaneamente, reduzindo o tempo de execuÃ§Ã£o em mais de 90%.
* **SessÃµes Persistentes:** Uso de `requests.Session` com **Connection Pooling**, permitindo o reuso de conexÃµes TCP (Keep-Alive) e reduzindo a latÃªncia nas requisiÃ§Ãµes ao servidor do MEC.
* **ResiliÃªncia a Fuso HorÃ¡rio:** Configurado com `zoneinfo` para operar rigorosamente no fuso de **BrasÃ­lia (UTC-3)**, garantindo a integridade do histÃ³rico mesmo quando executado em servidores internacionais (GitHub/Streamlit).
* **HistÃ³rico Incremental Inteligente:** O sistema identifica se os dados do dia jÃ¡ foram coletados e utiliza uma lÃ³gica de *Skip* para evitar redundÃ¢ncia e desperdÃ­cio de recursos.

## ğŸ“‚ Estrutura do Projeto

```text
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ history/     # CSVs com histÃ³rico incremental (uma coluna por dia)
â”‚   â”œâ”€â”€ mappings/    # JSONs de mapeamento de IDs de cursos
â”‚   â””â”€â”€ reports/     # RelatÃ³rios TXT formatados do Ãºltimo ciclo de sync
â””â”€â”€ src/
    â”œâ”€â”€ providers/    # Provedores de dados (Consumo de APIs externas)
    â”œâ”€â”€ controller.py # CÃ©rebro do projeto (MVC - Controller)
    â”œâ”€â”€ repository.py # Camada de persistÃªncia (DAL)
    â””â”€â”€ cron_sync.py  # Script de automaÃ§Ã£o e rotinas em lote
    â””â”€â”€ app.py        # Dashboard Streamlit (MVC - View)
```

## ğŸ¤– AutomaÃ§Ã£o e Hospedagem

* **ExecuÃ§Ã£o:** O projeto utiliza **GitHub Actions** para rodar o processo de coleta automaticamente todos os dias. O workflow realiza o setup, executa a sincronizaÃ§Ã£o e faz o commit automÃ¡tico dos novos dados para o repositÃ³rio.
* **Hospedagem:** O dashboard de visualizaÃ§Ã£o estÃ¡ hospedado no **Streamlit Cloud**, integrado diretamente ao repositÃ³rio para atualizaÃ§Ãµes contÃ­nuas.

---

### ğŸ“ Notas de Desenvolvimento
O projeto foi otimizado para respeitar limites de taxa (Rate Limiting) da API oficial, utilizando um pool de no mÃ¡ximo 10 conexÃµes simultÃ¢neas, garantindo a coleta sem risco de bloqueio de IP.